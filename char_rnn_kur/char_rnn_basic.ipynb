{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Making-and-Viewing-data\" data-toc-modified-id=\"Making-and-Viewing-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Making and Viewing data</a></div><div class=\"lev1 toc-item\"><a href=\"#Defaults-kurfile-as-basis\" data-toc-modified-id=\"Defaults-kurfile-as-basis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Defaults kurfile as basis</a></div><div class=\"lev1 toc-item\"><a href=\"#Use-50-chars-to-learn-1-char:-pytorch\" data-toc-modified-id=\"Use-50-chars-to-learn-1-char:-pytorch-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Use 50 chars to learn 1 char: pytorch</a></div><div class=\"lev1 toc-item\"><a href=\"#Use-50-chars-to-learn-1-char:-keras\" data-toc-modified-id=\"Use-50-chars-to-learn-1-char:-keras-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Use 50 chars to learn 1 char: keras</a></div><div class=\"lev1 toc-item\"><a href=\"#Model-use-gru-instead-of-lstm\" data-toc-modified-id=\"Model-use-gru-instead-of-lstm-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model use gru instead of lstm</a></div><div class=\"lev1 toc-item\"><a href=\"#Use-50-chars-to-learn-another-50-chars\" data-toc-modified-id=\"Use-50-chars-to-learn-another-50-chars-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Use 50 chars to learn another 50 chars</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Making and Viewing data\n",
    "- books/ for text files is at same level as this notebook\n",
    "- download books/ with the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": true,
     "read_only": true
    }
   },
   "outputs": [],
   "source": [
    "!svn checkout https://github.com/deepgram/kur/trunk/examples/language-model/books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare Dataset**\n",
    "- vocab = 30, meaning there are 30 unique chars, 26 letters, 4 symbols\n",
    "- create cleaned.txt: remove all other symbols outside of 30 above\n",
    "- create `data/` , inside we have `train.jsonl`, `validate.jsonl`, `evaluate.jsonl`, `test.jsonl` \n",
    "- seq_len = 50, meaning there are 50 timesteps as a sequence to predict next char or next 50 chars \n",
    "- `vocab` and `seq_len` are set inside `make_data.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T10:53:57.320578Z",
     "start_time": "2017-03-09T18:53:39.734526+08:00"
    },
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": true,
     "read_only": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :\n",
      "sample Index: 0 13299\n",
      "dims:\n",
      "(13299, 50, 30)\n",
      "(13299, 30)\n",
      "validate :\n",
      "sample Index: 13299 14130\n",
      "dims:\n",
      "(831, 50, 30)\n",
      "(831, 30)\n",
      "test :\n",
      "sample Index: 14130 14961\n",
      "dims:\n",
      "(831, 50, 30)\n",
      "(831, 30)\n",
      "evaluate :\n",
      "sample Index: 14961 15792\n",
      "dims:\n",
      "(831, 50, 30)\n",
      "(831, 30)\n"
     ]
    }
   ],
   "source": [
    "# create dataset, to change seq_len, go inside make_data.py to change directly\n",
    "!python utils_func/make_data.py\n",
    "\n",
    "# sample index is shown\n",
    "# each dataset dimension is shown\n",
    "# in each dataset section, first dim is in_seq, second dim is out_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View Inputs and targets data**\n",
    "- Let's see what the preprocessed data sample look like before entering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T10:54:32.016078Z",
     "start_time": "2017-03-09T18:54:25.411425+08:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": true,
     "read_only": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "peek at train:\n",
      "------\n",
      "\"the project gutenberg ebook of pride and prejudice\" --> \" \"\n",
      "{'in_seq': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 1, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])}\n",
      "in_seq --> out_char\n",
      "{'out_char': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0])}\n",
      "------\n",
      "\" particular resentment by his having slighted one \" --> \"o\"\n",
      "{'in_seq': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])}\n",
      "in_seq --> out_char\n",
      "{'out_char': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0])}\n",
      "\n",
      "\n",
      "peek at validate:\n",
      "------\n",
      "\"particular resentment by his having slighted one o\" --> \"f\"\n",
      "{'in_seq': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])}\n",
      "in_seq --> out_char\n",
      "{'out_char': array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0])}\n",
      "------\n",
      "\"ngley for a kingdom upon my honour i never met wit\" --> \"h\"\n",
      "{'in_seq': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])}\n",
      "in_seq --> out_char\n",
      "{'out_char': array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0])}\n",
      "\n",
      "\n",
      "peek at test:\n",
      "------\n",
      "\"gley for a kingdom upon my honour i never met with\" --> \" \"\n",
      "{'in_seq': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])}\n",
      "in_seq --> out_char\n",
      "{'out_char': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0])}\n",
      "------\n",
      "\"ting your time with me. mr. bingley followed his a\" --> \"d\"\n",
      "{'in_seq': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0]])}\n",
      "in_seq --> out_char\n",
      "{'out_char': array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0])}\n",
      "\n",
      "\n",
      "peek at evaluate:\n",
      "------\n",
      "\"ing your time with me. mr. bingley followed his ad\" --> \"v\"\n",
      "{'in_seq': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])}\n",
      "in_seq --> out_char\n",
      "{'out_char': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0])}\n",
      "------\n",
      "\"hey had yet learnt to care for at a ball. they ret\" --> \"u\"\n",
      "{'in_seq': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])}\n",
      "in_seq --> out_char\n",
      "{'out_char': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python utils_func/view_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Defaults kurfile as basis\n",
    "- t1/defaults.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T12:51:42.940007Z",
     "start_time": "2017-03-09T20:51:42.930300+08:00"
    },
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting t1/defaults.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile t1/defaults.yaml\n",
    "\n",
    "\n",
    "# ANSWER: \n",
    "# solution1: error display when change from lstm to gru works \n",
    "# solution2: change backend to tensorflow backend, can help with the model loss is NaN issue too\n",
    "\n",
    "---\n",
    "                                                ##### setting section\n",
    "settings:\n",
    "    \n",
    "  backend: pytorch    \n",
    "    \n",
    "    \n",
    "    \n",
    "  num_epochs: 1                    # leave it empty means inf number of epochs\n",
    "                                 # so to use default value, just comment this line out\n",
    "#   drop_neurons: 0.5\n",
    "#   grad_clip: 5\n",
    "\n",
    "\n",
    "         \n",
    "                                                # 30 unique chars in the whole corpose\n",
    "  vocab:                                         \n",
    "    size: 30                          \n",
    "\n",
    "\n",
    "\n",
    "                                                # 128 neurons for each rnn layer\n",
    "                                                # 3 rnn layers in total\n",
    "  rnn:\n",
    "    size: 128                                    \n",
    "    depth: 3                                     \n",
    "        \n",
    "        \n",
    "        \n",
    "  folder_name: t1  \n",
    "    \n",
    "  last_seq: no  \n",
    "\n",
    "        \n",
    "#####################################################################################\n",
    "\n",
    "\n",
    "model:\n",
    "  - input: in_seq\n",
    "\n",
    "\n",
    "  - for:\n",
    "      range: \"{{ rnn.depth - 1 }}\"\n",
    "      iterate:\n",
    "        - recurrent:\n",
    "            size: \"{{ rnn.size }}\"\n",
    "            type: \"{{ rnn.type|default('lstm') }}\"   #  lstm\n",
    "                                                        # yes: return 30 characters on a sequence\n",
    "            sequence: yes                             \n",
    "            bidirectional: no\n",
    "                                                        # -1: refer to last dimension\n",
    "                                                        # however, no idea why last dim \n",
    "        - batch_normalization:\n",
    "            axis: -1\n",
    "#         - dropout: \"{{drop_neurons}}\"\n",
    "\n",
    "  - recurrent:\n",
    "      size: \"{{ rnn.size }}\"\n",
    "      type: \"{{ rnn.type|default('lstm') }}\"   #  lstm\n",
    "                                                        # no: just return the last character on a sequence\n",
    "      sequence: \"{{last_seq}}\"                          \n",
    "      bidirectional: no\n",
    "  - batch_normalization\n",
    "#   - dropout: \"{{drop_neurons}}\"\n",
    "    \n",
    "                                                        # now it is like 30 class-classification problem\n",
    "                                                        # that's why we need 30 neurons here\n",
    "  - dense: \"{{vocab.size}}\"                    \n",
    "                                                 \n",
    "\n",
    "  - activation: softmax\n",
    "\n",
    "  - output: out_char                              \n",
    "           \n",
    " ######################################################################################################       \n",
    "        \n",
    "                                                ##### loss section\n",
    "            \n",
    "            \n",
    "                                                # use softmax and crossentropy to calc loss\n",
    "                                                # target data is under variable `out_char`\n",
    "loss:\n",
    "  - target: out_char\n",
    "    name: categorical_crossentropy\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "                                                ##### train section\n",
    "        \n",
    "train:\n",
    "                                                \n",
    "  data:\n",
    "    - jsonl: data/train.jsonl\n",
    "        \n",
    "                                                \n",
    "  epochs: \"{{ num_epochs|default(5) }}\"     \n",
    "    \n",
    "    \n",
    "  weights:\n",
    "    initial: \"{{folder_name}}/best.w.kur\"      \n",
    "                                                # no need to save the best weights wrt training set\n",
    "    last: \"{{folder_name}}/last.w.kur\"\n",
    "        \n",
    "        \n",
    "                                                # produce and save info on loss for plotting loss vs batches...\n",
    "  log: \"{{folder_name}}/log\"\n",
    "    \n",
    "    \n",
    "  optimizer: \n",
    "    name: adam    \n",
    "#     clip:                                              \n",
    "#       norm: \"{{grad_clip}}\"   \n",
    "        \n",
    "                                                # save plot on loss vs batches on both training and validation set\n",
    "  hooks:                                   \n",
    "    - plot: \"{{folder_name}}/loss.png\"\n",
    "        \n",
    "                               \n",
    "                                                ##### validate section\n",
    "\n",
    "validate:\n",
    "    \n",
    "  data:\n",
    "    - jsonl: data/validate.jsonl\n",
    "        \n",
    "  weights: \"{{folder_name}}/best.w.kur\"\n",
    "\n",
    "                                                ##### test section\n",
    "test:\n",
    "    \n",
    "  data:\n",
    "    - jsonl: data/test.jsonl\n",
    "        \n",
    "  weights: \n",
    "    initial: \"{{folder_name}}/best.w.kur\"\n",
    "\n",
    "                                                ##### evaluate section\n",
    "evaluate:\n",
    "    \n",
    "  data:\n",
    "    - jsonl: data/evaluate.jsonl\n",
    "        \n",
    "  weights: \n",
    "    initial: \"{{folder_name}}/best.w.kur\"\n",
    "                                                # use output_hook to produce predictions along with true labels or targets \n",
    "  destination: \"{{folder_name}}/output.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Use 50 chars to learn 1 char: pytorch\n",
    "**Attention**\n",
    "- use pytoch\n",
    "- train 2 epochs\n",
    "\n",
    "**Question!**\n",
    "- input sample dim is correct (50, 30), but\n",
    "- The model layer dimension look strange, see `kur -vv build ` output below, especially the number `512`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T11:38:41.536378Z",
     "start_time": "2017-03-09T19:38:41.523954+08:00"
    },
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing t1/pytorch_50_1.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile t1/pytorch_50_1.yaml\n",
    "\n",
    "---\n",
    "settings: \n",
    "  num_epochs: 2\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "include: defaults.yaml\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T11:38:49.468076Z",
     "start_time": "2017-03-09T19:38:42.246479+08:00"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-09 19:38:43,087 kur.kurfile:699]\u001b[0m Parsing source: t1/pytorch_50_1.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:38:43,090 kur.kurfile:699]\u001b[0m Parsing source: defaults.yaml, included by t1/pytorch_50_1.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:38:43,108 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:43,108 kur.kurfile:784]\u001b[0m Parsing Kurfile section: settings\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:43,109 kur.kurfile:784]\u001b[0m Parsing Kurfile section: train\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:43,115 kur.kurfile:784]\u001b[0m Parsing Kurfile section: validate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:43,116 kur.kurfile:784]\u001b[0m Parsing Kurfile section: test\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:43,118 kur.kurfile:784]\u001b[0m Parsing Kurfile section: evaluate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:43,122 kur.containers.layers.placeholder:63]\u001b[0m Using short-hand name for placeholder: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:43,123 kur.containers.layers.placeholder:97]\u001b[0m Placeholder \"in_seq\" has a deferred shape.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:43,137 kur.containers.layers.output:50]\u001b[0m Using short-hand name for output: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:43,138 kur.kurfile:784]\u001b[0m Parsing Kurfile section: loss\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:38:43,140 kur.__main__:96]\u001b[0m Trying to build a \"train\" model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,111 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 32\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,111 kur.backend.backend:187]\u001b[0m Using backend: pytorch\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:38:49,112 kur.backend.backend:80]\u001b[0m Creating backend: pytorch\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:38:49,112 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:38:49,218 kur.model.model:261]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:38:49,218 kur.model.model:266]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,218 kur.model.model:273]\u001b[0m Assembled Node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,218 kur.model.model:275]\u001b[0m   Uses: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,218 kur.model.model:277]\u001b[0m   Used by: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,219 kur.model.model:278]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,219 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:275]\u001b[0m   Uses: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:275]\u001b[0m   Uses: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:277]\u001b[0m   Used by: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:275]\u001b[0m   Uses: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:277]\u001b[0m   Used by: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,220 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.1, ..for.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:275]\u001b[0m   Uses: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:277]\u001b[0m   Used by: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:273]\u001b[0m Assembled Node: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:277]\u001b[0m   Used by: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:278]\u001b[0m   Aliases: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,221 kur.model.model:273]\u001b[0m Assembled Node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,222 kur.model.model:275]\u001b[0m   Uses: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,222 kur.model.model:277]\u001b[0m   Used by: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,222 kur.model.model:278]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,222 kur.model.model:273]\u001b[0m Assembled Node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,222 kur.model.model:275]\u001b[0m   Uses: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,222 kur.model.model:277]\u001b[0m   Used by: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,222 kur.model.model:278]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:38:49,223 kur.model.model:281]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,223 kur.model.model:312]\u001b[0m Building node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,223 kur.model.model:313]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,223 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,223 kur.model.model:126]\u001b[0m Trying to infer shape for input \"in_seq\"\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,223 kur.model.model:144]\u001b[0m Inferred shape for input \"in_seq\": (50, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,224 kur.containers.layers.placeholder:114]\u001b[0m Inferred shape: (50, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,224 kur.model.model:385]\u001b[0m   Value: {'layer': <function TorchModel.placeholder.<locals>.calculate at 0x1100c4f28>, 'shape': (50, 30)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,224 kur.model.model:312]\u001b[0m Building node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,224 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,225 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,225 kur.model.model:316]\u001b[0m   - in_seq: {'layer': <function TorchModel.placeholder.<locals>.calculate at 0x1100c4f28>, 'shape': (50, 30)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,229 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['in_seq'] feed into ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,229 kur.model.model:385]\u001b[0m   Value: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x11730d6a8>, 'shape': (50, 128)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,230 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,230 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,231 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,231 kur.model.model:316]\u001b[0m   - ..recurrent.0: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x11730d6a8>, 'shape': (50, 128)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,232 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..recurrent.0'] feed into swap_channels\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,232 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['swap_channels'] feed into ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,233 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..batch_normalization.0'] feed into swap_channels\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,233 kur.model.model:385]\u001b[0m   Value: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x11730d8c8>, 'shape': (50, 128)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,233 kur.model.model:312]\u001b[0m Building node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,233 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,233 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,233 kur.model.model:316]\u001b[0m   - ..batch_normalization.0: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x11730d8c8>, 'shape': (50, 128)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,236 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['swap_channels'] feed into ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,236 kur.model.model:385]\u001b[0m   Value: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x11730da60>, 'shape': (50, 128)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,236 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,237 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.1, ..for.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,237 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,237 kur.model.model:316]\u001b[0m   - ..recurrent.1: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x11730da60>, 'shape': (50, 128)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,237 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..recurrent.1'] feed into swap_channels\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,239 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['swap_channels'] feed into ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,239 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..batch_normalization.1'] feed into swap_channels\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,239 kur.model.model:385]\u001b[0m   Value: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x11730dc80>, 'shape': (50, 128)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,240 kur.model.model:312]\u001b[0m Building node: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,241 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,241 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,241 kur.model.model:316]\u001b[0m   - ..batch_normalization.1: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x11730dc80>, 'shape': (50, 128)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,245 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['swap_channels'] feed into ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,245 kur.model.model:385]\u001b[0m   Value: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x11730de18>, 'shape': (128,)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,246 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,246 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,246 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,246 kur.model.model:316]\u001b[0m   - ..recurrent.2: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x11730de18>, 'shape': (128,)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,246 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..recurrent.2'] feed into ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,247 kur.model.model:385]\u001b[0m   Value: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x11730df28>, 'shape': (128,)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,248 kur.model.model:312]\u001b[0m Building node: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,249 kur.model.model:313]\u001b[0m   Aliases: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,249 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,249 kur.model.model:316]\u001b[0m   - ..batch_normalization.2: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x11730df28>, 'shape': (128,)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,249 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..batch_normalization.2'] feed into ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,249 kur.model.model:385]\u001b[0m   Value: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1173160d0>, 'shape': (30,)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,250 kur.model.model:312]\u001b[0m Building node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,250 kur.model.model:313]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,250 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,250 kur.model.model:316]\u001b[0m   - ..dense.0: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1173160d0>, 'shape': (30,)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,250 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..dense.0'] feed into log_softmax\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,251 kur.model.model:385]\u001b[0m   Value: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1173161e0>, 'shape': (30,)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,251 kur.model.model:312]\u001b[0m Building node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,251 kur.model.model:313]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,251 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,251 kur.model.model:316]\u001b[0m   - ..activation.0: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1173161e0>, 'shape': (30,)}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,251 kur.model.model:385]\u001b[0m   Value: {'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1173161e0>, 'shape': (30,)}\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:38:49,251 kur.model.model:285]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:38:49,251 kur.model.model:286]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,251 kur.model.executor:101]\u001b[0m Recompiling the model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,252 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['log_softmax'] feed into bundle\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,252 kur.backend.pytorch_backend:339]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,252 kur.backend.pytorch_backend:343]\u001b[0m Layer Name                     | Shape                | Parameters\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,252 kur.backend.pytorch_backend:345]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,252 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_0.weight_ih_ | (512, 30)            | 15360     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,252 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,252 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_0.weight_hh_ | (512, 128)           | 65536     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,252 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,252 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_0.bias_ih_l0 | (512,)               | 512       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,252 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,252 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_0.bias_hh_l0 | (512,)               | 512       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_0. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_0. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_0. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_0. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_1.weight_ih_ | (512, 128)           | 65536     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_1.weight_hh_ | (512, 128)           | 65536     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_1.bias_ih_l0 | (512,)               | 512       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_1.bias_hh_l0 | (512,)               | 512       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,253 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,254 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_1. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,254 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,254 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_1. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,254 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,254 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_1. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,254 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,254 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_1. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,254 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,254 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_2.weight_ih_ | (512, 128)           | 65536     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,254 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_2.weight_hh_ | (512, 128)           | 65536     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_2.bias_ih_l0 | (512,)               | 512       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_2.bias_hh_l0 | (512,)               | 512       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_2. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_2. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_2. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_2. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,255 kur.backend.pytorch_backend:350]\u001b[0m layer___dense_0.weight         | (30, 128)            | 3840      \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,256 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,256 kur.backend.pytorch_backend:350]\u001b[0m layer___dense_0.bias           | (30,)                | 30        \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,256 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:38:49,256 kur.backend.pytorch_backend:354]\u001b[0m Total parameters: 351518\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kur -vv build t1/pytorch_50_1.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Use 50 chars to learn 1 char: keras\n",
    "**Attention**\n",
    "- use keras\n",
    "- train 2 epochs\n",
    "- `kur -vv build ` output has no number `512`, and looks more intuitive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T11:44:55.111229Z",
     "start_time": "2017-03-09T19:44:55.103223+08:00"
    },
    "code_folding": [
     0
    ],
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing t2/keras_50_1.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile t2/keras_50_1.yaml\n",
    "\n",
    "---\n",
    "settings: \n",
    "  backend: keras\n",
    "\n",
    "  folder_name: t2\n",
    "include: ../t1/defaults.yaml\n",
    "...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T11:45:37.331098Z",
     "start_time": "2017-03-09T19:44:56.888246+08:00"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-09 19:44:57,691 kur.kurfile:699]\u001b[0m Parsing source: t2/keras_50_1.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:44:57,694 kur.kurfile:699]\u001b[0m Parsing source: ../t1/defaults.yaml, included by t2/keras_50_1.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:44:57,710 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:44:57,710 kur.kurfile:784]\u001b[0m Parsing Kurfile section: settings\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:44:57,711 kur.kurfile:784]\u001b[0m Parsing Kurfile section: train\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:44:57,715 kur.kurfile:784]\u001b[0m Parsing Kurfile section: validate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:44:57,716 kur.kurfile:784]\u001b[0m Parsing Kurfile section: test\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:44:57,717 kur.kurfile:784]\u001b[0m Parsing Kurfile section: evaluate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:44:57,721 kur.containers.layers.placeholder:63]\u001b[0m Using short-hand name for placeholder: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:44:57,722 kur.containers.layers.placeholder:97]\u001b[0m Placeholder \"in_seq\" has a deferred shape.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:44:57,730 kur.containers.layers.output:50]\u001b[0m Using short-hand name for output: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:44:57,730 kur.kurfile:784]\u001b[0m Parsing Kurfile section: loss\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:44:57,732 kur.__main__:96]\u001b[0m Trying to build a \"train\" model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:03,570 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 32\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:03,571 kur.backend.backend:187]\u001b[0m Using backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:45:03,571 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:45:03,571 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:45:03,571 kur.backend.keras_backend:122]\u001b[0m No particular backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:03,572 kur.backend.keras_backend:124]\u001b[0m Using the system-default Keras backend.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:03,572 kur.backend.keras_backend:189]\u001b[0m Overriding environmental variables: {'THEANO_FLAGS': None, 'KERAS_BACKEND': None, 'TF_CPP_MIN_LOG_LEVEL': '1'}\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:45:04,116 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: theano\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:45:04,117 kur.model.model:261]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:45:04,117 kur.model.model:266]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,117 kur.model.model:273]\u001b[0m Assembled Node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,117 kur.model.model:275]\u001b[0m   Uses: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,117 kur.model.model:277]\u001b[0m   Used by: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,117 kur.model.model:278]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,117 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,117 kur.model.model:275]\u001b[0m   Uses: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,117 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,117 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,117 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,117 kur.model.model:275]\u001b[0m   Uses: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:277]\u001b[0m   Used by: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:275]\u001b[0m   Uses: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:277]\u001b[0m   Used by: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.1, ..for.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:275]\u001b[0m   Uses: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:277]\u001b[0m   Used by: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:273]\u001b[0m Assembled Node: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:277]\u001b[0m   Used by: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,118 kur.model.model:278]\u001b[0m   Aliases: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:273]\u001b[0m Assembled Node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:275]\u001b[0m   Uses: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:277]\u001b[0m   Used by: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:278]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:273]\u001b[0m Assembled Node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:275]\u001b[0m   Uses: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:277]\u001b[0m   Used by: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:278]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:45:04,119 kur.model.model:281]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:312]\u001b[0m Building node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:313]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.containers.layers.placeholder:164]\u001b[0m Creating placeholder for \"in_seq\" with data type \"float32\".\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:126]\u001b[0m Trying to infer shape for input \"in_seq\"\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.model.model:144]\u001b[0m Inferred shape for input \"in_seq\": (50, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,119 kur.containers.layers.placeholder:114]\u001b[0m Inferred shape: (50, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,121 kur.model.model:385]\u001b[0m   Value: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,121 kur.model.model:312]\u001b[0m Building node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,121 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,121 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,121 kur.model.model:316]\u001b[0m   - in_seq: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,450 kur.model.model:385]\u001b[0m   Value: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,451 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,451 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,451 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,451 kur.model.model:316]\u001b[0m   - ..recurrent.0: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,462 kur.model.model:385]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,462 kur.model.model:312]\u001b[0m Building node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,462 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,462 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,462 kur.model.model:316]\u001b[0m   - ..batch_normalization.0: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,527 kur.model.model:385]\u001b[0m   Value: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,527 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,527 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.1, ..for.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,527 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,527 kur.model.model:316]\u001b[0m   - ..recurrent.1: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,542 kur.model.model:385]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,542 kur.model.model:312]\u001b[0m Building node: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,542 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,542 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,542 kur.model.model:316]\u001b[0m   - ..batch_normalization.1: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,597 kur.model.model:385]\u001b[0m   Value: Subtensor{int64}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,597 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,597 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,597 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,597 kur.model.model:316]\u001b[0m   - ..recurrent.2: Subtensor{int64}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,606 kur.model.model:385]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,606 kur.model.model:312]\u001b[0m Building node: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,606 kur.model.model:313]\u001b[0m   Aliases: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,606 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,606 kur.model.model:316]\u001b[0m   - ..batch_normalization.2: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,608 kur.model.model:385]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,608 kur.model.model:312]\u001b[0m Building node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,608 kur.model.model:313]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,608 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,608 kur.model.model:316]\u001b[0m   - ..dense.0: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,608 kur.model.model:385]\u001b[0m   Value: Softmax.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,609 kur.model.model:312]\u001b[0m Building node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,609 kur.model.model:313]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,609 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,609 kur.model.model:316]\u001b[0m   - ..activation.0: Softmax.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,609 kur.model.model:385]\u001b[0m   Value: Softmax.0\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:45:04,609 kur.model.model:285]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:45:04,609 kur.model.model:286]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,609 kur.model.executor:101]\u001b[0m Recompiling the model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:04,609 kur.backend.keras_backend:527]\u001b[0m Instantiating a Keras model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m Layer (type)                     Output Shape          Param #     Connected to                     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ====================================================================================================\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m in_seq (InputLayer)              (None, 50, 30)        0                                            \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ..recurrent.0 (LSTM)             (None, 50, 128)       81408       in_seq[0][0]                     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.0 (BatchNo (None, 50, 128)       512         ..recurrent.0[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ..recurrent.1 (LSTM)             (None, 50, 128)       131584      ..batch_normalization.0[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.1 (BatchNo (None, 50, 128)       512         ..recurrent.1[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ..recurrent.2 (LSTM)             (None, 128)           131584      ..batch_normalization.1[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.2 (BatchNo (None, 128)           512         ..recurrent.2[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,450 kur.backend.keras_backend:538]\u001b[0m ..dense.0 (Dense)                (None, 30)            3870        ..batch_normalization.2[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,451 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,451 kur.backend.keras_backend:538]\u001b[0m ..activation.0 (Activation)      (None, 30)            0           ..dense.0[0][0]                  \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,451 kur.backend.keras_backend:538]\u001b[0m ====================================================================================================\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,451 kur.backend.keras_backend:538]\u001b[0m Total params: 349,982\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,451 kur.backend.keras_backend:538]\u001b[0m Trainable params: 349,214\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,451 kur.backend.keras_backend:538]\u001b[0m Non-trainable params: 768\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,451 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,451 kur.backend.keras_backend:538]\u001b[0m \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,451 kur.backend.keras_backend:576]\u001b[0m Assembling a training function from the model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:06,454 kur.backend.keras_backend:509]\u001b[0m Adding additional inputs: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:35,456 kur.backend.keras_backend:599]\u001b[0m Additional inputs for log functions: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:35,456 kur.backend.keras_backend:616]\u001b[0m Expected input shapes: in_seq=(None, 50, 30), out_char=(None, None)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:35,456 kur.backend.keras_backend:634]\u001b[0m Compiled model: {'shapes': {'input': [(None, 50, 30), (None, None)]}, 'names': {'input': ['in_seq', 'out_char'], 'output': ['..activation.0', 'out_char']}, 'func': <keras.backend.theano_backend.Function object at 0x119f29518>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:35,457 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:35,457 kur.providers.batch_provider:102]\u001b[0m Maximum number of batches set to: 1\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:45:35,492 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:35,492 kur.providers.batch_provider:139]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 19:45:35,492 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kur -vv build t2/keras_50_1.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train with 1 epochs**\n",
    "**Attention**\n",
    "- to train lstm layers\n",
    "- pytorch is fast\n",
    "- if use keras, must use tensorflow backend\n",
    "- but very slow compared to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T11:50:27.262044Z",
     "start_time": "2017-03-09T19:50:27.252600+08:00"
    },
    "code_folding": [
     0
    ],
    "collapsed": false,
    "run_control": {
     "frozen": true,
     "read_only": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting t2/keras_50_1.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile t2/keras_50_1.yaml\n",
    "\n",
    "---\n",
    "settings: \n",
    "  backend: \n",
    "    name: keras\n",
    "    backend: tensorflow\n",
    "\n",
    "  num_epochs: 1  \n",
    "    \n",
    "  folder_name: t2\n",
    "include: ../t1/defaults.yaml\n",
    "...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T11:54:32.327994Z",
     "start_time": "2017-03-09T19:50:28.128417+08:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": true,
     "read_only": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-09 19:50:28,907 kur.kurfile:699]\u001b[0m Parsing source: t2/keras_50_1.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:28,911 kur.kurfile:699]\u001b[0m Parsing source: ../t1/defaults.yaml, included by t2/keras_50_1.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:28,927 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:28,964 kur.loggers.binary_logger:71]\u001b[0m Loading log data: t2/log\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:34,751 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:34,751 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:34,751 kur.backend.keras_backend:81]\u001b[0m The tensorflow backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:36,030 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: tensorflow\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:36,030 kur.model.model:261]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:36,030 kur.model.model:266]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:36,031 kur.model.model:281]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:37,269 kur.model.model:285]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:37,269 kur.model.model:286]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:37,269 kur.kurfile:357]\u001b[0m Ignoring missing initial weights: t2/best.w.kur. If this is undesireable, set \"must_exist\" to \"yes\" in the approriate \"weights\" section.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:37,269 kur.model.executor:315]\u001b[0m No historical training loss available from logs.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:37,270 kur.model.executor:323]\u001b[0m No historical validation loss available from logs.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:37,270 kur.model.executor:329]\u001b[0m No previous epochs.\u001b[0m\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "\u001b[1;37m[INFO 2017-03-09 19:50:46,508 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "\n",
      "Epoch 1/1, loss=3.227: 100%|| 13299/13299 [03:38<00:00, 51.12samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-09 19:54:25,843 kur.model.executor:464]\u001b[0m Training loss: 3.227\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:54:26,044 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "Validating, loss=2.912: 100%|| 831/831 [00:03<00:00, 198.93samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-09 19:54:29,616 kur.model.executor:197]\u001b[0m Validation loss: 2.912\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:54:29,616 kur.model.executor:413]\u001b[0m Saving best historical validation weights: t2/best.w.kur\u001b[0m\n",
      "Completed 1 epochs.\n",
      "\u001b[1;37m[INFO 2017-03-09 19:54:30,283 kur.model.executor:235]\u001b[0m Saving most recent weights: t2/last.w.kur\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kur -v train t2/keras_50_1.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Evaluating and Viewing result**\n",
    "- evaluate once and output.pkl is produced\n",
    "- use view_output function to see how well trained model predict next char\n",
    "    - view_output will compare prediction with targets\n",
    "    - print them in comparison nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T11:56:39.402854Z",
     "start_time": "2017-03-09T19:56:31.293000+08:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": true,
     "read_only": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-09 19:56:32,202 kur.kurfile:699]\u001b[0m Parsing source: t2/keras_50_1.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:32,205 kur.kurfile:699]\u001b[0m Parsing source: ../t1/defaults.yaml, included by t2/keras_50_1.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:32,221 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:32,570 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:32,570 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:32,570 kur.backend.keras_backend:81]\u001b[0m The tensorflow backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:33,648 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: tensorflow\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:33,648 kur.model.model:261]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:33,648 kur.model.model:266]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:33,648 kur.model.model:281]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:34,751 kur.model.model:285]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:34,751 kur.model.model:286]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:35,500 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "Evaluating: 100%|| 831/831 [00:03<00:00, 261.05samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-09 19:56:38,983 kur.model.hooks.output_hook:40]\u001b[0m Saving model output as pickle: t2/output.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kur -v evaluate t2/keras_50_1.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T11:56:50.750963Z",
     "start_time": "2017-03-09T19:56:50.024937+08:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": true,
     "read_only": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"ing your time with me. mr. bingley followed his ad\" --> \" \"\r\n",
      "                                                       INCORRECT (v)\r\n",
      "\"ng your time with me. mr. bingley followed his adv\" --> \" \"\r\n",
      "                                                       INCORRECT (i)\r\n",
      "\"g your time with me. mr. bingley followed his advi\" --> \" \"\r\n",
      "                                                       INCORRECT (c)\r\n",
      "\" your time with me. mr. bingley followed his advic\" --> \" \"\r\n",
      "                                                       INCORRECT (e)\r\n",
      "\"your time with me. mr. bingley followed his advice\" --> \" \"\r\n",
      "                                                       INCORRECT (.)\r\n",
      "\"our time with me. mr. bingley followed his advice.\" --> \" \"\r\n",
      "                                                       CORRECT\r\n",
      "\"ur time with me. mr. bingley followed his advice. \" --> \" \"\r\n",
      "                                                       INCORRECT (m)\r\n",
      "\"r time with me. mr. bingley followed his advice. m\" --> \" \"\r\n",
      "                                                       INCORRECT (r)\r\n",
      "\" time with me. mr. bingley followed his advice. mr\" --> \" \"\r\n",
      "                                                       INCORRECT (.)\r\n",
      "\"time with me. mr. bingley followed his advice. mr.\" --> \" \"\r\n",
      "                                                       CORRECT\r\n",
      "accuracy = 0.16967509025270758\r\n"
     ]
    }
   ],
   "source": [
    "# viewing result from evaluation: \n",
    "!python utils_func/view_outputs.py 't2/output.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T11:59:55.903235Z",
     "start_time": "2017-03-09T19:59:47.794519+08:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": true,
     "read_only": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-09 19:59:48,605 kur.kurfile:699]\u001b[0m Parsing source: t2/keras_50_1.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:48,609 kur.kurfile:699]\u001b[0m Parsing source: ../t1/defaults.yaml, included by t2/keras_50_1.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:48,625 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:48,975 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:48,975 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:48,975 kur.backend.keras_backend:81]\u001b[0m The tensorflow backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:50,200 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: tensorflow\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:50,200 kur.model.model:261]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:50,200 kur.model.model:266]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:50,201 kur.model.model:281]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:51,350 kur.model.model:285]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:51,350 kur.model.model:286]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:52,121 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "Testing, loss=2.876: 100%|| 831/831 [00:03<00:00, 281.79samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-09 19:59:55,486 kur.model.executor:197]\u001b[0m Test loss: 2.876\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kur -v test t2/keras_50_1.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model use gru instead of lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T13:05:15.629514Z",
     "start_time": "2017-03-09T21:05:15.621935+08:00"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting t3/gru_theano.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile t3/gru_theano.yaml\n",
    "\n",
    "---\n",
    "settings:\n",
    "  backend: keras\n",
    "    \n",
    "  folder_name: t3\n",
    "  rnn:\n",
    "    type: gru\n",
    "        \n",
    "  num_epochs: 2\n",
    "\n",
    "include: ../t1/defaults.yaml     \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T12:57:43.150573Z",
     "start_time": "2017-03-09T20:57:12.656411+08:00"
    },
    "collapsed": true,
    "run_control": {
     "frozen": true,
     "read_only": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-09 20:57:13,677 kur.kurfile:699]\u001b[0m Parsing source: t3/gru_theano.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:13,681 kur.kurfile:699]\u001b[0m Parsing source: ../t1/defaults.yaml, included by t3/gru_theano.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:13,699 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:13,700 kur.kurfile:784]\u001b[0m Parsing Kurfile section: settings\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:13,702 kur.kurfile:784]\u001b[0m Parsing Kurfile section: train\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:13,708 kur.kurfile:784]\u001b[0m Parsing Kurfile section: validate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:13,710 kur.kurfile:784]\u001b[0m Parsing Kurfile section: test\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:13,712 kur.kurfile:784]\u001b[0m Parsing Kurfile section: evaluate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:13,716 kur.containers.layers.placeholder:63]\u001b[0m Using short-hand name for placeholder: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:13,717 kur.containers.layers.placeholder:97]\u001b[0m Placeholder \"in_seq\" has a deferred shape.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:13,738 kur.containers.layers.output:50]\u001b[0m Using short-hand name for output: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:13,741 kur.kurfile:784]\u001b[0m Parsing Kurfile section: loss\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:13,744 kur.__main__:96]\u001b[0m Trying to build a \"train\" model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:19,219 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 32\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:19,219 kur.backend.backend:187]\u001b[0m Using backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:19,220 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:19,220 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:19,220 kur.backend.keras_backend:122]\u001b[0m No particular backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:19,220 kur.backend.keras_backend:124]\u001b[0m Using the system-default Keras backend.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:19,220 kur.backend.keras_backend:189]\u001b[0m Overriding environmental variables: {'THEANO_FLAGS': None, 'KERAS_BACKEND': None, 'TF_CPP_MIN_LOG_LEVEL': '1'}\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:20,360 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: theano\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:20,360 kur.model.model:261]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:20,360 kur.model.model:266]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,361 kur.model.model:273]\u001b[0m Assembled Node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,361 kur.model.model:275]\u001b[0m   Uses: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,361 kur.model.model:277]\u001b[0m   Used by: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,361 kur.model.model:278]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,361 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,361 kur.model.model:275]\u001b[0m   Uses: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,361 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,361 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,361 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,362 kur.model.model:275]\u001b[0m   Uses: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,363 kur.model.model:277]\u001b[0m   Used by: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,363 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,363 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,363 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,363 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,364 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,364 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,364 kur.model.model:275]\u001b[0m   Uses: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,364 kur.model.model:277]\u001b[0m   Used by: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,364 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.1, ..for.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,364 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,364 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,364 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,364 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,365 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,365 kur.model.model:275]\u001b[0m   Uses: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,365 kur.model.model:277]\u001b[0m   Used by: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,365 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,365 kur.model.model:273]\u001b[0m Assembled Node: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,365 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,365 kur.model.model:277]\u001b[0m   Used by: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,365 kur.model.model:278]\u001b[0m   Aliases: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,365 kur.model.model:273]\u001b[0m Assembled Node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,366 kur.model.model:275]\u001b[0m   Uses: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,366 kur.model.model:277]\u001b[0m   Used by: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,366 kur.model.model:278]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,366 kur.model.model:273]\u001b[0m Assembled Node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,366 kur.model.model:275]\u001b[0m   Uses: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,366 kur.model.model:277]\u001b[0m   Used by: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,366 kur.model.model:278]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:20,366 kur.model.model:281]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,367 kur.model.model:312]\u001b[0m Building node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,367 kur.model.model:313]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,367 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,367 kur.containers.layers.placeholder:164]\u001b[0m Creating placeholder for \"in_seq\" with data type \"float32\".\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,367 kur.model.model:126]\u001b[0m Trying to infer shape for input \"in_seq\"\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,367 kur.model.model:144]\u001b[0m Inferred shape for input \"in_seq\": (50, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,367 kur.containers.layers.placeholder:114]\u001b[0m Inferred shape: (50, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,373 kur.model.model:385]\u001b[0m   Value: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,373 kur.model.model:312]\u001b[0m Building node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,373 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,373 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,374 kur.model.model:316]\u001b[0m   - in_seq: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,807 kur.model.model:385]\u001b[0m   Value: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,807 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,808 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,808 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,808 kur.model.model:316]\u001b[0m   - ..recurrent.0: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,847 kur.model.model:385]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,847 kur.model.model:312]\u001b[0m Building node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,848 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,848 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,848 kur.model.model:316]\u001b[0m   - ..batch_normalization.0: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,937 kur.model.model:385]\u001b[0m   Value: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,937 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,937 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.1, ..for.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,937 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,937 kur.model.model:316]\u001b[0m   - ..recurrent.1: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,949 kur.model.model:385]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,949 kur.model.model:312]\u001b[0m Building node: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,949 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,949 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:20,949 kur.model.model:316]\u001b[0m   - ..batch_normalization.1: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,042 kur.model.model:385]\u001b[0m   Value: Subtensor{int64}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,042 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,042 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,042 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,042 kur.model.model:316]\u001b[0m   - ..recurrent.2: Subtensor{int64}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,072 kur.model.model:385]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,072 kur.model.model:312]\u001b[0m Building node: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,072 kur.model.model:313]\u001b[0m   Aliases: ..dense.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,072 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,072 kur.model.model:316]\u001b[0m   - ..batch_normalization.2: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,086 kur.model.model:385]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,086 kur.model.model:312]\u001b[0m Building node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,086 kur.model.model:313]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,087 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,087 kur.model.model:316]\u001b[0m   - ..dense.0: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,087 kur.model.model:385]\u001b[0m   Value: Softmax.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,087 kur.model.model:312]\u001b[0m Building node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,088 kur.model.model:313]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,088 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,088 kur.model.model:316]\u001b[0m   - ..activation.0: Softmax.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,088 kur.model.model:385]\u001b[0m   Value: Softmax.0\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:21,089 kur.model.model:285]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:21,089 kur.model.model:286]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,089 kur.model.executor:101]\u001b[0m Recompiling the model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:21,089 kur.backend.keras_backend:527]\u001b[0m Instantiating a Keras model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,968 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,968 kur.backend.keras_backend:538]\u001b[0m Layer (type)                     Output Shape          Param #     Connected to                     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,968 kur.backend.keras_backend:538]\u001b[0m ====================================================================================================\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,968 kur.backend.keras_backend:538]\u001b[0m in_seq (InputLayer)              (None, 50, 30)        0                                            \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,968 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ..recurrent.0 (GRU)              (None, 50, 128)       61056       in_seq[0][0]                     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.0 (BatchNo (None, 50, 128)       512         ..recurrent.0[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ..recurrent.1 (GRU)              (None, 50, 128)       98688       ..batch_normalization.0[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.1 (BatchNo (None, 50, 128)       512         ..recurrent.1[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ..recurrent.2 (GRU)              (None, 128)           98688       ..batch_normalization.1[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.2 (BatchNo (None, 128)           512         ..recurrent.2[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ..dense.0 (Dense)                (None, 30)            3870        ..batch_normalization.2[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ..activation.0 (Activation)      (None, 30)            0           ..dense.0[0][0]                  \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ====================================================================================================\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m Total params: 263,838\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m Trainable params: 263,070\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m Non-trainable params: 768\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,969 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,970 kur.backend.keras_backend:538]\u001b[0m \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,970 kur.backend.keras_backend:576]\u001b[0m Assembling a training function from the model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:22,975 kur.backend.keras_backend:509]\u001b[0m Adding additional inputs: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:41,681 kur.backend.keras_backend:599]\u001b[0m Additional inputs for log functions: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:41,681 kur.backend.keras_backend:616]\u001b[0m Expected input shapes: in_seq=(None, 50, 30), out_char=(None, None)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:41,681 kur.backend.keras_backend:634]\u001b[0m Compiled model: {'shapes': {'input': [(None, 50, 30), (None, None)]}, 'func': <keras.backend.theano_backend.Function object at 0x11eb8ebe0>, 'names': {'input': ['in_seq', 'out_char'], 'output': ['..activation.0', 'out_char']}}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:41,681 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:41,681 kur.providers.batch_provider:102]\u001b[0m Maximum number of batches set to: 1\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 20:57:41,702 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:41,702 kur.providers.batch_provider:139]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 20:57:41,702 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kur -vv build t3/gru_theano.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much faster with gru**\n",
    "- 3 times faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T13:08:38.495436Z",
     "start_time": "2017-03-09T21:05:24.570464+08:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-09 21:05:25,595 kur.kurfile:699]\u001b[0m Parsing source: t3/gru_theano.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:25,599 kur.kurfile:699]\u001b[0m Parsing source: ../t1/defaults.yaml, included by t3/gru_theano.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:25,617 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:25,643 kur.loggers.binary_logger:107]\u001b[0m Log does not exist. Creating path: t3/log\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:32,554 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:32,555 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:32,555 kur.backend.keras_backend:122]\u001b[0m No particular backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:33,464 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: theano\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:33,464 kur.model.model:261]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:33,465 kur.model.model:266]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:33,465 kur.model.model:281]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:34,889 kur.model.model:285]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:34,889 kur.model.model:286]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:34,890 kur.kurfile:357]\u001b[0m Ignoring missing initial weights: t3/best.w.kur. If this is undesireable, set \"must_exist\" to \"yes\" in the approriate \"weights\" section.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:34,890 kur.model.executor:315]\u001b[0m No historical training loss available from logs.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:34,890 kur.model.executor:323]\u001b[0m No historical validation loss available from logs.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:34,890 kur.model.executor:329]\u001b[0m No previous epochs.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:05:57,434 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "\n",
      "Epoch 1/2, loss=2.517: 100%|| 13299/13299 [01:16<00:00, 174.27samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-09 21:07:14,035 kur.model.executor:464]\u001b[0m Training loss: 2.517\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:07:16,416 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "Validating, loss=2.041: 100%|| 831/831 [00:00<00:00, 964.39samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-09 21:07:17,296 kur.model.executor:197]\u001b[0m Validation loss: 2.041\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:07:17,296 kur.model.executor:413]\u001b[0m Saving best historical validation weights: t3/best.w.kur\u001b[0m\n",
      "\n",
      "Epoch 2/2, loss=1.837: 100%|| 13299/13299 [01:17<00:00, 170.67samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-09 21:08:35,628 kur.model.executor:464]\u001b[0m Training loss: 1.837\u001b[0m\n",
      "Validating, loss=1.857: 100%|| 831/831 [00:00<00:00, 1036.96samples/s]\n",
      "\u001b[1;37m[INFO 2017-03-09 21:08:36,436 kur.model.executor:197]\u001b[0m Validation loss: 1.857\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:08:36,436 kur.model.executor:413]\u001b[0m Saving best historical validation weights: t3/best.w.kur\u001b[0m\n",
      "Completed 2 epochs.\n",
      "\u001b[1;37m[INFO 2017-03-09 21:08:36,824 kur.model.executor:235]\u001b[0m Saving most recent weights: t3/last.w.kur\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kur -v train t3/gru_theano.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**QUESTION: How to generate long text** like karpathy did in [his post](https://hyp.is/KYLatAPxEee89XOhgBMapQ/karpathy.github.io/2015/05/21/rnn-effectiveness/)?\n",
    "- What I did above is similar to graph 1 on the left (SEE figure below), I use a model use 30 characters (index 1 to index 30) to predict the next (31th) character (in the graph I used 50, just so you know)\n",
    "- What I want to achieve in the next kurfile below is graph 2 in the middle, which is a model to use 30 characters (say index 1 to 30th) to predict 30 characters with index (2 to 31th)\n",
    "- to generate a long text like what karpathy did in the post link above, should I train my model like graph2 with much longer seq_len, say 200? Is it how karpathy got the long text??\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-08T11:12:52.699903Z",
     "start_time": "2017-03-08T19:12:52.681914+08:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://lh3.googleusercontent.com/Ybix_t5PBJaST4icd_BY8WvvFRfieba58Wkup2S1gpRf3mFdxp00iOtpWKdh6ptM9uexoTORCr8mfQL4Qy4oeiIzIZxtGFXgZsSA34g3teyBhJ_fxqQphwxpPyCsa7q4t530EE4BT8XiceQwoAuCl1PhBFR-2UA4NfZZiL5hyrVeXOdoRSzZ1jl45MekOaHad-9j1A5_PNMeOZz8BmLx3Uc5xFWNrdlZ0rSql385Sum81rdntmMUWY8MnN7LYzr96IlgN3Hxd0uQZkbc5pn6YD8LTew_7xlSGBiYxqIoc2qfjmFd_mWr-RP445kq_firczCmjHows4aOsKw0yK-DaOBCGc-ovUv9c_1OFqYQYKGHk6VTMf3TF3gP4X2g0tOk4K6zHP3MSTZGpvEj1-HGCq8kVPwBXVnj1jI-nKnLwIiVePlbYt8qAls4uhoOXGJb5Nm4gotIoOTsBdR1NRYiULuUghcIjbWy22uCA-2CbO59oOLf-dXXHO9brhOutFUP5Mazt3BQk6SOUQbf7tqbqsRWlp7iMXdC0kwXEeUiNGSw0caNKOPjhg2z-GBAqDoCrmuc9YZQ1UyI-UZr-ppyNLVXaecRfjePylfNyp1eFjx8p2ccJ5xo=w1912-h1352-no\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='https://lh3.googleusercontent.com/Ybix_t5PBJaST4icd_BY8WvvFRfieba58Wkup2S1gpRf3mFdxp00iOtpWKdh6ptM9uexoTORCr8mfQL4Qy4oeiIzIZxtGFXgZsSA34g3teyBhJ_fxqQphwxpPyCsa7q4t530EE4BT8XiceQwoAuCl1PhBFR-2UA4NfZZiL5hyrVeXOdoRSzZ1jl45MekOaHad-9j1A5_PNMeOZz8BmLx3Uc5xFWNrdlZ0rSql385Sum81rdntmMUWY8MnN7LYzr96IlgN3Hxd0uQZkbc5pn6YD8LTew_7xlSGBiYxqIoc2qfjmFd_mWr-RP445kq_firczCmjHows4aOsKw0yK-DaOBCGc-ovUv9c_1OFqYQYKGHk6VTMf3TF3gP4X2g0tOk4K6zHP3MSTZGpvEj1-HGCq8kVPwBXVnj1jI-nKnLwIiVePlbYt8qAls4uhoOXGJb5Nm4gotIoOTsBdR1NRYiULuUghcIjbWy22uCA-2CbO59oOLf-dXXHO9brhOutFUP5Mazt3BQk6SOUQbf7tqbqsRWlp7iMXdC0kwXEeUiNGSw0caNKOPjhg2z-GBAqDoCrmuc9YZQ1UyI-UZr-ppyNLVXaecRfjePylfNyp1eFjx8p2ccJ5xo=w1912-h1352-no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Use 50 chars to learn another 50 chars\n",
    "\n",
    "**Error**\n",
    "- see below\n",
    "\n",
    "**Possible solutions**\n",
    "- [one](https://github.com/deepgram/kur/issues/13)\n",
    "- [another](https://github.com/deepgram/kur/issues/23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**keras-theano**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T13:12:23.122734Z",
     "start_time": "2017-03-09T21:12:23.112392+08:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting t4/theano_50_50.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile t4/theano_50_50.yaml\n",
    "\n",
    "---\n",
    "\n",
    "settings: \n",
    "  backend: keras\n",
    "    \n",
    "  folder_name: t4  \n",
    "    \n",
    "  last_seq: yes  \n",
    "    \n",
    "  rnn:\n",
    "    type: gru\n",
    "    \n",
    "  num_epochs: 1                    # leave it empty means inf number of epochs\n",
    "                                 # so to use default value, just comment this line out\n",
    "#   drop_neurons: 0.5\n",
    "#   grad_clip: 5\n",
    "\n",
    "\n",
    "model:\n",
    "  - input: in_seq\n",
    "\n",
    "\n",
    "  - for:\n",
    "      range: \"{{ rnn.depth - 1 }}\"\n",
    "      iterate:\n",
    "        - recurrent:\n",
    "            size: \"{{ rnn.size }}\"\n",
    "            type: \"{{ rnn.type|default('lstm') }}\"   #  lstm\n",
    "                                                        # yes: return 30 characters on a sequence\n",
    "            sequence: yes                             \n",
    "            bidirectional: no\n",
    "                                                        # -1: refer to last dimension\n",
    "                                                        # however, no idea why last dim \n",
    "        - batch_normalization:\n",
    "            axis: -1\n",
    "#         - dropout: \"{{drop_neurons}}\"\n",
    "\n",
    "  - recurrent:\n",
    "      size: \"{{ rnn.size }}\"\n",
    "      type: \"{{ rnn.type|default('lstm') }}\"   #  lstm\n",
    "                                                        # no: just return the last character on a sequence\n",
    "      sequence: \"{{last_seq}}\"                          \n",
    "      bidirectional: no\n",
    "  - batch_normalization\n",
    "#   - dropout: \"{{drop_neurons}}\"\n",
    "\n",
    "  \n",
    "                                                   # http://kur.deepgram.com/containers.html?highlight=parallel#parallel\n",
    "                                                   # Question!: how to understand the following code? \n",
    "                                                   # - apply a dense layer of 30 neurons to each char of the sequence (seq_len = 30)\n",
    "                                                   # seq_len is 30 defined when making data\n",
    "  - parallel:\n",
    "      apply:\n",
    "        - dense: \"{{vocab.size}}\"\n",
    "\n",
    "\n",
    "  \n",
    "  - activation: softmax\n",
    "\n",
    "  - output: out_char                              # make a name of output layer\n",
    "           \n",
    "\n",
    "include: ../t1/defaults.yaml\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build first**: Questions!\n",
    "- fails\n",
    "- keras provide sensible error message: `ValueError: Input dimension mis-match. (input[0].shape[1] = 30, input[1].shape[1] = 50)`\n",
    "- pytorch does not below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T13:12:58.029961Z",
     "start_time": "2017-03-09T21:12:24.130051+08:00"
    },
    "collapsed": false,
    "run_control": {
     "frozen": true,
     "read_only": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-09 21:12:25,093 kur.kurfile:699]\u001b[0m Parsing source: t4/theano_50_50.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:25,105 kur.kurfile:699]\u001b[0m Parsing source: ../t1/defaults.yaml, included by t4/theano_50_50.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:25,124 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:25,124 kur.kurfile:784]\u001b[0m Parsing Kurfile section: settings\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:25,126 kur.kurfile:784]\u001b[0m Parsing Kurfile section: train\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:25,132 kur.kurfile:784]\u001b[0m Parsing Kurfile section: validate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:25,134 kur.kurfile:784]\u001b[0m Parsing Kurfile section: test\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:25,137 kur.kurfile:784]\u001b[0m Parsing Kurfile section: evaluate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:25,142 kur.containers.layers.placeholder:63]\u001b[0m Using short-hand name for placeholder: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:25,143 kur.containers.layers.placeholder:97]\u001b[0m Placeholder \"in_seq\" has a deferred shape.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:25,173 kur.containers.layers.output:50]\u001b[0m Using short-hand name for output: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:25,175 kur.kurfile:784]\u001b[0m Parsing Kurfile section: loss\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:25,179 kur.__main__:96]\u001b[0m Trying to build a \"train\" model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:30,720 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 32\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:30,720 kur.backend.backend:187]\u001b[0m Using backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:30,721 kur.backend.backend:80]\u001b[0m Creating backend: keras\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:30,721 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:30,721 kur.backend.keras_backend:122]\u001b[0m No particular backend for Keras has been requested.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:30,721 kur.backend.keras_backend:124]\u001b[0m Using the system-default Keras backend.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:30,721 kur.backend.keras_backend:189]\u001b[0m Overriding environmental variables: {'TF_CPP_MIN_LOG_LEVEL': '1', 'KERAS_BACKEND': None, 'THEANO_FLAGS': None}\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:31,442 kur.backend.keras_backend:195]\u001b[0m Keras is loaded. The backend is: theano\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:31,443 kur.model.model:261]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:31,443 kur.model.model:266]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,443 kur.model.model:273]\u001b[0m Assembled Node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,443 kur.model.model:275]\u001b[0m   Uses: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,443 kur.model.model:277]\u001b[0m   Used by: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,443 kur.model.model:278]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,443 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:275]\u001b[0m   Uses: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:275]\u001b[0m   Uses: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:277]\u001b[0m   Used by: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:275]\u001b[0m   Uses: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:277]\u001b[0m   Used by: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.1, ..for.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,444 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:275]\u001b[0m   Uses: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:277]\u001b[0m   Used by: ..parallel.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:273]\u001b[0m Assembled Node: ..parallel.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:277]\u001b[0m   Used by: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:278]\u001b[0m   Aliases: ..parallel.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:273]\u001b[0m Assembled Node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:275]\u001b[0m   Uses: ..parallel.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:277]\u001b[0m   Used by: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:278]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:273]\u001b[0m Assembled Node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:275]\u001b[0m   Uses: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:277]\u001b[0m   Used by: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:278]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:31,445 kur.model.model:281]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,445 kur.model.model:312]\u001b[0m Building node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,446 kur.model.model:313]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,446 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,446 kur.containers.layers.placeholder:164]\u001b[0m Creating placeholder for \"in_seq\" with data type \"float32\".\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,446 kur.model.model:126]\u001b[0m Trying to infer shape for input \"in_seq\"\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,446 kur.model.model:144]\u001b[0m Inferred shape for input \"in_seq\": (50, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,446 kur.containers.layers.placeholder:114]\u001b[0m Inferred shape: (50, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,449 kur.model.model:385]\u001b[0m   Value: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,450 kur.model.model:312]\u001b[0m Building node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,450 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,450 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,450 kur.model.model:316]\u001b[0m   - in_seq: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,763 kur.model.model:385]\u001b[0m   Value: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,763 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,764 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,764 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,764 kur.model.model:316]\u001b[0m   - ..recurrent.0: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,787 kur.model.model:385]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,787 kur.model.model:312]\u001b[0m Building node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,788 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,788 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,788 kur.model.model:316]\u001b[0m   - ..batch_normalization.0: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,835 kur.model.model:385]\u001b[0m   Value: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,835 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,836 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.1, ..for.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,836 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,836 kur.model.model:316]\u001b[0m   - ..recurrent.1: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,864 kur.model.model:385]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,865 kur.model.model:312]\u001b[0m Building node: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,865 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,865 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,865 kur.model.model:316]\u001b[0m   - ..batch_normalization.1: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,919 kur.model.model:385]\u001b[0m   Value: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,919 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,919 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,919 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,919 kur.model.model:316]\u001b[0m   - ..recurrent.2: DimShuffle{1,0,2}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,952 kur.model.model:385]\u001b[0m   Value: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,952 kur.model.model:312]\u001b[0m Building node: ..parallel.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,952 kur.model.model:313]\u001b[0m   Aliases: ..parallel.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,952 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,952 kur.model.model:316]\u001b[0m   - ..batch_normalization.2: Elemwise{add,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,957 kur.model.model:385]\u001b[0m   Value: Reshape{3}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,957 kur.model.model:312]\u001b[0m Building node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,957 kur.model.model:313]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,958 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,958 kur.model.model:316]\u001b[0m   - ..parallel.0: Reshape{3}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,961 kur.model.model:385]\u001b[0m   Value: Elemwise{true_div,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,961 kur.model.model:312]\u001b[0m Building node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,961 kur.model.model:313]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,961 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,961 kur.model.model:316]\u001b[0m   - ..activation.0: Elemwise{true_div,no_inplace}.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,961 kur.model.model:385]\u001b[0m   Value: Elemwise{true_div,no_inplace}.0\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:31,961 kur.model.model:285]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:31,962 kur.model.model:286]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,962 kur.model.executor:101]\u001b[0m Recompiling the model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:31,962 kur.backend.keras_backend:527]\u001b[0m Instantiating a Keras model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,058 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,058 kur.backend.keras_backend:538]\u001b[0m Layer (type)                     Output Shape          Param #     Connected to                     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,058 kur.backend.keras_backend:538]\u001b[0m ====================================================================================================\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,058 kur.backend.keras_backend:538]\u001b[0m in_seq (InputLayer)              (None, 50, 30)        0                                            \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,058 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,058 kur.backend.keras_backend:538]\u001b[0m ..recurrent.0 (GRU)              (None, 50, 128)       61056       in_seq[0][0]                     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,058 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,060 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.0 (BatchNo (None, 50, 128)       512         ..recurrent.0[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,060 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,060 kur.backend.keras_backend:538]\u001b[0m ..recurrent.1 (GRU)              (None, 50, 128)       98688       ..batch_normalization.0[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,060 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,060 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.1 (BatchNo (None, 50, 128)       512         ..recurrent.1[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,060 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,060 kur.backend.keras_backend:538]\u001b[0m ..recurrent.2 (GRU)              (None, 50, 128)       98688       ..batch_normalization.1[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:538]\u001b[0m ..batch_normalization.2 (BatchNo (None, 50, 128)       512         ..recurrent.2[0][0]              \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:538]\u001b[0m ..parallel.0_..dense.0_0_0 (Time (None, 50, 30)        3870        ..batch_normalization.2[0][0]    \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:538]\u001b[0m ..activation.0 (Activation)      (None, 50, 30)        0           ..parallel.0_..dense.0_0_0[0][0] \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:538]\u001b[0m ====================================================================================================\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:538]\u001b[0m Total params: 263,838\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:538]\u001b[0m Trainable params: 263,070\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:538]\u001b[0m Non-trainable params: 768\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:538]\u001b[0m ____________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:538]\u001b[0m \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,061 kur.backend.keras_backend:576]\u001b[0m Assembling a training function from the model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:35,067 kur.backend.keras_backend:509]\u001b[0m Adding additional inputs: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:56,615 kur.backend.keras_backend:599]\u001b[0m Additional inputs for log functions: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:56,615 kur.backend.keras_backend:616]\u001b[0m Expected input shapes: in_seq=(None, 50, 30), out_char=(None, None, None)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:56,615 kur.backend.keras_backend:634]\u001b[0m Compiled model: {'names': {'output': ['..activation.0', 'out_char'], 'input': ['in_seq', 'out_char']}, 'func': <keras.backend.theano_backend.Function object at 0x11db1f978>, 'shapes': {'input': [(None, 50, 30), (None, None, None)]}}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:56,615 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:56,616 kur.providers.batch_provider:102]\u001b[0m Maximum number of batches set to: 1\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:12:56,629 kur.backend.keras_backend:666]\u001b[0m Waiting for model to finish compiling...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:56,629 kur.providers.batch_provider:139]\u001b[0m Preparing next batch of data...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:12:56,629 kur.providers.batch_provider:204]\u001b[0m Next batch of data has been prepared.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/theano/compile/function_module.py\", line 859, in __call__\n",
      "    outputs = self.fn()\n",
      "ValueError: Input dimension mis-match. (input[0].shape[1] = 30, input[1].shape[1] = 50)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/bin/kur\", line 11, in <module>\n",
      "    load_entry_point('kur', 'console_scripts', 'kur')()\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/__main__.py\", line 382, in main\n",
      "    sys.exit(args.func(args) or 0)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/__main__.py\", line 126, in build\n",
      "    target.compile()\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/model/executor.py\", line 107, in compile\n",
      "    **kwargs\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/keras_backend.py\", line 639, in compile\n",
      "    self.wait_for_compile(model, key)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/keras_backend.py\", line 668, in wait_for_compile\n",
      "    self.run_batch(model, batch, key, False)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/keras_backend.py\", line 710, in run_batch\n",
      "    outputs = compiled['func'](inputs)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/keras/backend/theano_backend.py\", line 959, in __call__\n",
      "    return self.function(*inputs)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/theano/compile/function_module.py\", line 871, in __call__\n",
      "    storage_map=getattr(self.fn, 'storage_map', None))\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/theano/gof/link.py\", line 314, in raise_with_op\n",
      "    reraise(exc_type, exc_value, exc_trace)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/six.py\", line 685, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/theano/compile/function_module.py\", line 859, in __call__\n",
      "    outputs = self.fn()\n",
      "ValueError: Input dimension mis-match. (input[0].shape[1] = 30, input[1].shape[1] = 50)\n",
      "Apply node that caused the error: Elemwise{Composite{(i0 * log(i1))}}(out_char, Elemwise{clip,no_inplace}.0)\n",
      "Toposort index: 335\n",
      "Inputs types: [TensorType(float32, 3D), TensorType(float32, 3D)]\n",
      "Inputs shapes: [(2, 30, 1), (2, 50, 30)]\n",
      "Inputs strides: [(120, 4, 4), (6000, 120, 4)]\n",
      "Inputs values: ['not shown', 'not shown']\n",
      "Outputs clients: [[Sum{axis=[2], acc_dtype=float64}(Elemwise{Composite{(i0 * log(i1))}}.0)]]\n",
      "\n",
      "HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\n",
      "HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\n"
     ]
    }
   ],
   "source": [
    "!kur -vv build t4/theano_50_50.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using pytorch**     \n",
    "Questions!:     \n",
    "- no error reported in building models, but has strange dim number 384 in debug information\n",
    "- training fails, but error message is not helpful below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T13:15:49.803608Z",
     "start_time": "2017-03-09T21:15:49.770964+08:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing t5/pytorch_50_50.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile t5/pytorch_50_50.yaml\n",
    "\n",
    "---\n",
    "settings: \n",
    "  folder_name: t5\n",
    "\n",
    "  backend: pytorch\n",
    "    \n",
    "include: ../t4/theano_50_50.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T13:16:10.922870Z",
     "start_time": "2017-03-09T21:16:03.881248+08:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-09 21:16:04,847 kur.kurfile:699]\u001b[0m Parsing source: t5/pytorch_50_50.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:16:04,850 kur.kurfile:699]\u001b[0m Parsing source: ../t4/theano_50_50.yaml, included by t5/pytorch_50_50.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:16:04,858 kur.kurfile:699]\u001b[0m Parsing source: ../t1/defaults.yaml, included by t5/../t4/theano_50_50.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:16:04,875 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:04,875 kur.kurfile:784]\u001b[0m Parsing Kurfile section: settings\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:04,877 kur.kurfile:784]\u001b[0m Parsing Kurfile section: train\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:04,882 kur.kurfile:784]\u001b[0m Parsing Kurfile section: validate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:04,883 kur.kurfile:784]\u001b[0m Parsing Kurfile section: test\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:04,884 kur.kurfile:784]\u001b[0m Parsing Kurfile section: evaluate\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:04,887 kur.containers.layers.placeholder:63]\u001b[0m Using short-hand name for placeholder: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:04,888 kur.containers.layers.placeholder:97]\u001b[0m Placeholder \"in_seq\" has a deferred shape.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:04,903 kur.containers.layers.output:50]\u001b[0m Using short-hand name for output: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:04,904 kur.kurfile:784]\u001b[0m Parsing Kurfile section: loss\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:16:04,906 kur.__main__:96]\u001b[0m Trying to build a \"train\" model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,521 kur.providers.batch_provider:57]\u001b[0m Batch size set to: 32\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,522 kur.backend.backend:187]\u001b[0m Using backend: pytorch\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:16:10,522 kur.backend.backend:80]\u001b[0m Creating backend: pytorch\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:16:10,522 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:16:10,670 kur.model.model:261]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:16:10,670 kur.model.model:266]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,670 kur.model.model:273]\u001b[0m Assembled Node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,670 kur.model.model:275]\u001b[0m   Uses: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,671 kur.model.model:277]\u001b[0m   Used by: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,671 kur.model.model:278]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,671 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,671 kur.model.model:275]\u001b[0m   Uses: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,671 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,671 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,671 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,671 kur.model.model:275]\u001b[0m   Uses: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,671 kur.model.model:277]\u001b[0m   Used by: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,671 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,672 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,672 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,673 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,673 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,673 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,673 kur.model.model:275]\u001b[0m   Uses: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,674 kur.model.model:277]\u001b[0m   Used by: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,674 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.1, ..for.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,674 kur.model.model:273]\u001b[0m Assembled Node: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,674 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,674 kur.model.model:277]\u001b[0m   Used by: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,674 kur.model.model:278]\u001b[0m   Aliases: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,674 kur.model.model:273]\u001b[0m Assembled Node: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,674 kur.model.model:275]\u001b[0m   Uses: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,675 kur.model.model:277]\u001b[0m   Used by: ..parallel.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,675 kur.model.model:278]\u001b[0m   Aliases: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,675 kur.model.model:273]\u001b[0m Assembled Node: ..parallel.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,675 kur.model.model:275]\u001b[0m   Uses: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,675 kur.model.model:277]\u001b[0m   Used by: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,675 kur.model.model:278]\u001b[0m   Aliases: ..parallel.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,675 kur.model.model:273]\u001b[0m Assembled Node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,675 kur.model.model:275]\u001b[0m   Uses: ..parallel.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,675 kur.model.model:277]\u001b[0m   Used by: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,675 kur.model.model:278]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,676 kur.model.model:273]\u001b[0m Assembled Node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,676 kur.model.model:275]\u001b[0m   Uses: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,676 kur.model.model:277]\u001b[0m   Used by: \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,676 kur.model.model:278]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:16:10,676 kur.model.model:281]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,676 kur.model.model:312]\u001b[0m Building node: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,676 kur.model.model:313]\u001b[0m   Aliases: in_seq\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,676 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,676 kur.model.model:126]\u001b[0m Trying to infer shape for input \"in_seq\"\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,676 kur.model.model:144]\u001b[0m Inferred shape for input \"in_seq\": (50, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,676 kur.containers.layers.placeholder:114]\u001b[0m Inferred shape: (50, 30)\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,677 kur.model.model:385]\u001b[0m   Value: {'shape': (50, 30), 'layer': <function TorchModel.placeholder.<locals>.calculate at 0x10f495f28>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,677 kur.model.model:312]\u001b[0m Building node: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,677 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,677 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,677 kur.model.model:316]\u001b[0m   - in_seq: {'shape': (50, 30), 'layer': <function TorchModel.placeholder.<locals>.calculate at 0x10f495f28>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,682 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['in_seq'] feed into ..recurrent.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,682 kur.model.model:385]\u001b[0m   Value: {'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166dd8c8>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,682 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,682 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,683 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,683 kur.model.model:316]\u001b[0m   - ..recurrent.0: {'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166dd8c8>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,683 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..recurrent.0'] feed into swap_channels\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,686 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['swap_channels'] feed into ..batch_normalization.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,686 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..batch_normalization.0'] feed into swap_channels\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,686 kur.model.model:385]\u001b[0m   Value: {'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166ddae8>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,686 kur.model.model:312]\u001b[0m Building node: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,686 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,686 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,686 kur.model.model:316]\u001b[0m   - ..batch_normalization.0: {'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166ddae8>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,688 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['swap_channels'] feed into ..recurrent.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,688 kur.model.model:385]\u001b[0m   Value: {'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166ddc80>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,688 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,688 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.1, ..for.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,688 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,688 kur.model.model:316]\u001b[0m   - ..recurrent.1: {'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166ddc80>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,688 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..recurrent.1'] feed into swap_channels\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,689 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['swap_channels'] feed into ..batch_normalization.1\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,689 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..batch_normalization.1'] feed into swap_channels\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,689 kur.model.model:385]\u001b[0m   Value: {'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166ddea0>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,689 kur.model.model:312]\u001b[0m Building node: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,689 kur.model.model:313]\u001b[0m   Aliases: ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,689 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,689 kur.model.model:316]\u001b[0m   - ..batch_normalization.1: {'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166ddea0>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,690 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['swap_channels'] feed into ..recurrent.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,690 kur.model.model:385]\u001b[0m   Value: {'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166e50d0>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,690 kur.model.model:312]\u001b[0m Building node: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,691 kur.model.model:313]\u001b[0m   Aliases: ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,691 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,691 kur.model.model:316]\u001b[0m   - ..recurrent.2: {'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166e50d0>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,691 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..recurrent.2'] feed into swap_channels\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,691 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['swap_channels'] feed into ..batch_normalization.2\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,691 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['..batch_normalization.2'] feed into swap_channels\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,691 kur.model.model:385]\u001b[0m   Value: {'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166e52f0>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,691 kur.model.model:312]\u001b[0m Building node: ..parallel.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,691 kur.model.model:313]\u001b[0m   Aliases: ..parallel.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,691 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,691 kur.model.model:316]\u001b[0m   - ..batch_normalization.2: {'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166e52f0>}\u001b[0m\n",
      "[{'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166e52f0>}]\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,691 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['swap_channels'] feed into func\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,692 kur.model.model:385]\u001b[0m   Value: {'shape': (50, 30), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166e5510>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,692 kur.model.model:312]\u001b[0m Building node: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,692 kur.model.model:313]\u001b[0m   Aliases: ..activation.0\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,692 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,692 kur.model.model:316]\u001b[0m   - ..parallel.0: {'shape': (50, 30), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166e5510>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,692 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['func'] feed into log_softmax\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,692 kur.model.model:385]\u001b[0m   Value: {'shape': (50, 30), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166e5620>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,692 kur.model.model:312]\u001b[0m Building node: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,692 kur.model.model:313]\u001b[0m   Aliases: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,692 kur.model.model:314]\u001b[0m   Inputs:\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,692 kur.model.model:316]\u001b[0m   - ..activation.0: {'shape': (50, 30), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166e5620>}\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,692 kur.model.model:385]\u001b[0m   Value: {'shape': (50, 30), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x1166e5620>}\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:16:10,692 kur.model.model:285]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:16:10,692 kur.model.model:286]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,693 kur.model.executor:101]\u001b[0m Recompiling the model.\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,693 kur.backend.pytorch.modules:245]\u001b[0m Connecting layers: ['log_softmax'] feed into bundle\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,693 kur.backend.pytorch_backend:339]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,693 kur.backend.pytorch_backend:343]\u001b[0m Layer Name                     | Shape                | Parameters\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,693 kur.backend.pytorch_backend:345]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,693 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_0.weight_ih_ | (384, 30)            | 11520     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,693 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,693 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_0.weight_hh_ | (384, 128)           | 49152     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,693 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,693 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_0.bias_ih_l0 | (384,)               | 384       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_0.bias_hh_l0 | (384,)               | 384       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_0. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_0. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_0. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_0. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_1.weight_ih_ | (384, 128)           | 49152     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_1.weight_hh_ | (384, 128)           | 49152     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_1.bias_ih_l0 | (384,)               | 384       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,694 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_1.bias_hh_l0 | (384,)               | 384       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_1. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_1. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_1. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_1. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_2.weight_ih_ | (384, 128)           | 49152     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_2.weight_hh_ | (384, 128)           | 49152     \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_2.bias_ih_l0 | (384,)               | 384       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,695 kur.backend.pytorch_backend:350]\u001b[0m layer___recurrent_2.bias_hh_l0 | (384,)               | 384       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,696 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,696 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_2. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,696 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,696 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_2. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,696 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,696 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_2. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,696 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,696 kur.backend.pytorch_backend:350]\u001b[0m layer___batch_normalization_2. | (128,)               | 128       \u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,696 kur.backend.pytorch_backend:352]\u001b[0m -------------------------------+----------------------+-----------\u001b[0m\n",
      "\u001b[1;34m[DEBUG 2017-03-09 21:16:10,696 kur.backend.pytorch_backend:354]\u001b[0m Total parameters: 261120\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!kur -vv build t5/pytorch_50_50.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T13:18:24.022569Z",
     "start_time": "2017-03-09T21:18:15.972476+08:00"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;37m[INFO 2017-03-09 21:18:16,974 kur.kurfile:699]\u001b[0m Parsing source: t5/pytorch_50_50.yaml, included by top-level.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:16,978 kur.kurfile:699]\u001b[0m Parsing source: ../t4/theano_50_50.yaml, included by t5/pytorch_50_50.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:16,990 kur.kurfile:699]\u001b[0m Parsing source: ../t1/defaults.yaml, included by t5/../t4/theano_50_50.yaml.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:17,008 kur.kurfile:82]\u001b[0m Parsing Kurfile...\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:17,032 kur.loggers.binary_logger:107]\u001b[0m Log does not exist. Creating path: t5/log\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:22,713 kur.backend.backend:80]\u001b[0m Creating backend: pytorch\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:22,713 kur.backend.backend:83]\u001b[0m Backend variants: none\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:22,860 kur.model.model:261]\u001b[0m Enumerating the model containers.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:22,860 kur.model.model:266]\u001b[0m Assembling the model dependency graph.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:22,860 kur.model.model:281]\u001b[0m Connecting the model graph.\u001b[0m\n",
      "[{'shape': (50, 128), 'layer': <function TorchModel.add_operation.<locals>.stack.<locals>.calculate at 0x10c75eb70>}]\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:22,871 kur.model.model:285]\u001b[0m Model inputs:  in_seq\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:22,871 kur.model.model:286]\u001b[0m Model outputs: out_char\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:22,871 kur.kurfile:357]\u001b[0m Ignoring missing initial weights: t5/best.w.kur. If this is undesireable, set \"must_exist\" to \"yes\" in the approriate \"weights\" section.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:22,871 kur.model.executor:315]\u001b[0m No historical training loss available from logs.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:22,872 kur.model.executor:323]\u001b[0m No historical validation loss available from logs.\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:22,872 kur.model.executor:329]\u001b[0m No previous epochs.\u001b[0m\n",
      "\n",
      "Epoch 1/1, loss=N/A:   0%|                       | 0/13299 [00:00<?, ?samples/s]\u001b[1;31m[ERROR 2017-03-09 21:18:23,394 kur.model.executor:833]\u001b[0m Failed to execute on batch. Tolerating up to 2 more consecutive failures.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/model/executor.py\", line 822, in try_func\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch_backend.py\", line 382, in train\n",
      "    predictions, losses = torch_model.test(data, losses)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 144, in test\n",
      "    predictions = self.model(*inputs)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 202, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 54, in forward\n",
      "    return self.func(*inputs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in <listcomp>\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in <listcomp>\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 319, in func\n",
      "    return torch.cat(tuple(layer(X) for X in torch.unbind(x, 0)), 0)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/torch/functional.py\", line 68, in unbind\n",
      "    return tuple(tensor.select(dim, i) for i in _range(tensor.size(dim)))\n",
      "AttributeError: 'tuple' object has no attribute 'size'\u001b[0m\n",
      "\u001b[1;31m[ERROR 2017-03-09 21:18:23,516 kur.model.executor:833]\u001b[0m Failed to execute on batch. Tolerating up to 1 more consecutive failures.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/model/executor.py\", line 822, in try_func\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch_backend.py\", line 382, in train\n",
      "    predictions, losses = torch_model.test(data, losses)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 144, in test\n",
      "    predictions = self.model(*inputs)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 202, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 54, in forward\n",
      "    return self.func(*inputs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in <listcomp>\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in <listcomp>\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 319, in func\n",
      "    return torch.cat(tuple(layer(X) for X in torch.unbind(x, 0)), 0)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/torch/functional.py\", line 68, in unbind\n",
      "    return tuple(tensor.select(dim, i) for i in _range(tensor.size(dim)))\n",
      "AttributeError: 'tuple' object has no attribute 'size'\u001b[0m\n",
      "\u001b[1;31m[ERROR 2017-03-09 21:18:23,631 kur.model.executor:833]\u001b[0m Failed to execute on batch. Tolerating up to 0 more consecutive failures.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/model/executor.py\", line 822, in try_func\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch_backend.py\", line 382, in train\n",
      "    predictions, losses = torch_model.test(data, losses)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 144, in test\n",
      "    predictions = self.model(*inputs)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 202, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 54, in forward\n",
      "    return self.func(*inputs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in <listcomp>\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in <listcomp>\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 319, in func\n",
      "    return torch.cat(tuple(layer(X) for X in torch.unbind(x, 0)), 0)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/torch/functional.py\", line 68, in unbind\n",
      "    return tuple(tensor.select(dim, i) for i in _range(tensor.size(dim)))\n",
      "AttributeError: 'tuple' object has no attribute 'size'\u001b[0m\n",
      "\u001b[1;31m[ERROR 2017-03-09 21:18:23,745 kur.model.executor:829]\u001b[0m Failed to execute on batch. No more retries.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/model/executor.py\", line 822, in try_func\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch_backend.py\", line 382, in train\n",
      "    predictions, losses = torch_model.test(data, losses)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 144, in test\n",
      "    predictions = self.model(*inputs)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 202, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 54, in forward\n",
      "    return self.func(*inputs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in <listcomp>\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in <listcomp>\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 319, in func\n",
      "    return torch.cat(tuple(layer(X) for X in torch.unbind(x, 0)), 0)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/torch/functional.py\", line 68, in unbind\n",
      "    return tuple(tensor.select(dim, i) for i in _range(tensor.size(dim)))\n",
      "AttributeError: 'tuple' object has no attribute 'size'\u001b[0m\n",
      "\n",
      "\u001b[1;31m[ERROR 2017-03-09 21:18:23,747 kur.model.executor:227]\u001b[0m Exception raised during training.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/model/executor.py\", line 224, in train\n",
      "    **kwargs\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/model/executor.py\", line 586, in wrapped_train\n",
      "    model=self.model, data=batch)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/model/executor.py\", line 822, in try_func\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch_backend.py\", line 382, in train\n",
      "    predictions, losses = torch_model.test(data, losses)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 144, in test\n",
      "    predictions = self.model(*inputs)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 202, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 54, in forward\n",
      "    return self.func(*inputs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in <listcomp>\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in <listcomp>\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 319, in func\n",
      "    return torch.cat(tuple(layer(X) for X in torch.unbind(x, 0)), 0)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/torch/functional.py\", line 68, in unbind\n",
      "    return tuple(tensor.select(dim, i) for i in _range(tensor.size(dim)))\n",
      "AttributeError: 'tuple' object has no attribute 'size'\u001b[0m\n",
      "\u001b[1;37m[INFO 2017-03-09 21:18:23,748 kur.model.executor:235]\u001b[0m Saving most recent weights: t5/last.w.kur\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/bin/kur\", line 11, in <module>\n",
      "    load_entry_point('kur', 'console_scripts', 'kur')()\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/__main__.py\", line 382, in main\n",
      "    sys.exit(args.func(args) or 0)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/__main__.py\", line 62, in train\n",
      "    func(step=args.step)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/kurfile.py\", line 371, in func\n",
      "    return trainer.train(**defaults)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/model/executor.py\", line 224, in train\n",
      "    **kwargs\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/model/executor.py\", line 586, in wrapped_train\n",
      "    model=self.model, data=batch)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/model/executor.py\", line 822, in try_func\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch_backend.py\", line 382, in train\n",
      "    predictions, losses = torch_model.test(data, losses)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 144, in test\n",
      "    predictions = self.model(*inputs)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/torch/nn/modules/module.py\", line 202, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 54, in forward\n",
      "    return self.func(*inputs)\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in <listcomp>\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in <listcomp>\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 252, in calculate\n",
      "    result = operation(*[x(*inputs) for x in lower_layers])\n",
      "  File \"/Users/Natsume/Downloads/kur/kur/backend/pytorch/modules.py\", line 319, in func\n",
      "    return torch.cat(tuple(layer(X) for X in torch.unbind(x, 0)), 0)\n",
      "  File \"/Users/Natsume/miniconda2/envs/dlnd-tf-lab/lib/python3.5/site-packages/torch/functional.py\", line 68, in unbind\n",
      "    return tuple(tensor.select(dim, i) for i in _range(tensor.size(dim)))\n",
      "AttributeError: 'tuple' object has no attribute 'size'\n"
     ]
    }
   ],
   "source": [
    "!kur -v train t5/pytorch_50_50.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "char_rnn_basic.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "214px",
    "left": "984px",
    "right": "20px",
    "top": "25px",
    "width": "278px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
